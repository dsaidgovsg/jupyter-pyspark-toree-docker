versions:
- jupyter:   1.0.0
  spark:     2.4.1
  hadoop:    3.1.0
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.4.1
  hadoop:    2.7.3
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.4.0
  hadoop:    3.1.0
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.4.0
  hadoop:    2.7.3
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.3.3
  hadoop:    2.7.3
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.3.2
  hadoop:    2.7.3
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.3.1
  hadoop:    2.7.3
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.3.0
  hadoop:    2.7.3
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.2.3
  hadoop:    2.7.3
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.2.2
  hadoop:    2.7.3
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.2.1
  hadoop:    2.7.3
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.2.0
  hadoop:    2.7.3
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.1.3
  hadoop:    2.7.3
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.1.2
  hadoop:    2.7.3
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.1.1
  hadoop:    2.7.3
  with_hive: "true"

- jupyter:   1.0.0
  spark:     2.1.0
  hadoop:    2.7.3
  with_hive: "true"

# Spark version 2.0.z does not have pyspark distribution
