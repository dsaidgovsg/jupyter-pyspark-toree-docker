language: bash

env:
  global:
  - IMAGE_NAME=jupyter-pyspark-toree
  - FROM_DOCKER_IMAGE=guangie88/spark-custom-addons

matrix:
  include:
{%- for v in versions %}
{%- for jupyter in v.jupyter %}
{%- for spark in v.spark %}
{%- for scala in v.scala %}
{%- for hadoop in v.hadoop %}
{%- for python in v.python %}
{%- for with_hive in v.with_hive %}
  - services: docker
    env:
    - JUPYTER_VERSION={{ jupyter }}
    - SPARK_VERSION={{ spark }}
    - SCALA_VERSION={{ scala }}
    - HADOOP_VERSION={{ hadoop }}
    - PYTHON_VERSION={{ python }}
    - WITH_HIVE={{ with_hive }}
{%- endfor %}
{%- endfor %}
{%- endfor %}
{%- endfor %}
{%- endfor %}
{%- endfor %}
{%- endfor %}

script:
- shellcheck push-images.sh
- HIVE_TAG_SUFFIX="$(if [ "${WITH_HIVE}" = "true" ]; then echo _hive; fi)"
- TAG_NAME="${JUPYTER_VERSION}_spark-${SPARK_VERSION}_scala-${SCALA_VERSION}_hadoop-${HADOOP_VERSION}_python-${PYTHON_VERSION}${HIVE_TAG_SUFFIX}_debian"
- FROM_DOCKER_TAG="${SPARK_VERSION}_scala-${SCALA_VERSION}_hadoop-${HADOOP_VERSION}_python-${PYTHON_VERSION}${HIVE_TAG_SUFFIX}_pyspark_debian"
- PY4J_SRC="$(docker run --rm -t "${FROM_DOCKER_IMAGE}:${FROM_DOCKER_TAG}" sh -c 'ls ${SPARK_HOME}/python/lib/py4j* | sed -E "s/.+(py4j-.+)/\1/" | tr -d "\n"')"
- |
  docker build . -t "${DOCKER_USERNAME}/${IMAGE_NAME}:${TAG_NAME}" \
    --build-arg "FROM_DOCKER_IMAGE=${FROM_DOCKER_IMAGE}" \
    --build-arg "FROM_DOCKER_TAG=${FROM_DOCKER_TAG}" \
    --build-arg "JUPYTER_VERSION=${JUPYTER_VERSION}" \
    --build-arg "PY4J_SRC=${PY4J_SRC}" \
    ;

deploy:
  provider: script
  script: bash push-images.sh
  on:
    branch: master

branches:
  only:
  - master
