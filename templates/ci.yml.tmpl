name: CI

on:
  push:
    branches:
    - master
    - v*
  pull_request:
    branches:
    - master
    - v*

jobs:
  build:
    strategy:
      matrix:
        version:
{%- for v in versions %}
{%- for notebook in v.notebook %}
{%- for spark in v.spark %}
{%- for scala in v.scala %}
{%- for hadoop in v.hadoop %}
{%- for python in v.python %}
{%- for with_hive in v.with_hive %}
        - notebook:     "{{ notebook }}"
          spark:        "{{ spark }}"
          scala:        "{{ scala }}"
          hadoop:       "{{ hadoop }}"
          python:       "{{ python }}"
          with_hive:    "{{ with_hive }}"
{%- endfor %}
{%- endfor %}
{%- endfor %}
{%- endfor %}
{%- endfor %}
{%- endfor %}
{%- endfor %}
    runs-on: ubuntu-latest
    env:
      IMAGE_NAME: jupyter-pyspark-toree
      SELF_VERSION: "{{ self_version }}"
      BASE_VERSION: "{{ base_version }}"
      {% raw -%}
      NOTEBOOK_VERSION: "${{ matrix.version.notebook }}"
      SPARK_VERSION: "${{ matrix.version.spark }}"
      SCALA_VERSION: "${{ matrix.version.scala }}"
      HADOOP_VERSION: "${{ matrix.version.hadoop }}"
      PYTHON_VERSION: "${{ matrix.version.python }}"
      WITH_HIVE: "${{ matrix.version.with_hive }}"
      {%- endraw %}
    steps:
    - name: Checkout code
      uses: actions/checkout@v1
    - name: Install tera-cli
      run: |-
        wget https://github.com/guangie88/tera-cli/releases/download/v0.3.0/tera_linux_amd64 -O /tmp/tera
        chmod +x /tmp/tera
    - name: Check differences between ci.yml and ci.yml.tmpl
      run: |-
        cp .github/workflows/ci.yml .github/workflows/ci.yml.backup
        TERA=/tmp/tera ./templates/apply-vars.sh
        if ! diff .github/workflows/ci.yml .github/workflows/ci.yml.backup; then echo "ci.yml.tmpl and ci.yml differs!" && exit 1; fi
    - name: Shellcheck push image script
      run: shellcheck push-images.sh
    - name: Build Docker image
      # Alternative `ls ${SPARK_HOME}/python/lib/py4j* | sed -E "s/.+(py4j-.+)/\1/" | tr -d "\n"` in the container to get the py4j source zip file
      run: |-
        PY4J_SRC="$(curl -s https://github.com/apache/spark/tree/v${SPARK_VERSION}/python/lib | grep -oP 'py4j-\d+\.\d+\.\d+-src.zip' | head -1 | tr -d "\n")"
        if [ -z "${PY4J_SRC}" ]; then echo "PY4J_SRC must have a value" && exit 1; fi
        HIVE_TAG_SUFFIX="$(if [ "${WITH_HIVE}" = "true" ]; then echo _hive; fi)"
        TAG_NAME="${SELF_VERSION}_${NOTEBOOK_VERSION}_spark-${SPARK_VERSION}_scala-${SCALA_VERSION}_hadoop-${HADOOP_VERSION}_python-${PYTHON_VERSION}${HIVE_TAG_SUFFIX}_debian"
        docker build . -t "${IMAGE_NAME}:${TAG_NAME}" \
          --build-arg BASE_VERSION=${BASE_VERSION} \
          --build-arg NOTEBOOK_VERSION=${NOTEBOOK_VERSION} \
          --build-arg SPARK_VERSION=${SPARK_VERSION} \
          --build-arg SCALA_VERSION=${SCALA_VERSION} \
          --build-arg HADOOP_VERSION=${HADOOP_VERSION} \
          --build-arg PYTHON_VERSION=${PYTHON_VERSION} \
          --build-arg HIVE_TAG_SUFFIX=${HIVE_TAG_SUFFIX} \
          --build-arg PY4J_SRC=${PY4J_SRC}
        docker run --rm -t "${IMAGE_NAME}:${TAG_NAME}" python -c "import py4j; import pyspark"
    - name: Push Docker image
      run: |-
        export HIVE_TAG_SUFFIX="$(if [ "${WITH_HIVE}" = "true" ]; then echo _hive; fi)"
        bash push-images.sh
      env:
        {% raw -%}
        DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
        DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}
        IMAGE_ORG: ${{ secrets.IMAGE_ORG }}
        {%- endraw %}
      if: github.event_name == 'push'
